{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from src.pl_module import MelanomaModel\n",
    "from src.models.networks import Generator_auxGAN_512\n",
    "from src.transforms.albu import get_valid_transforms_with_resize\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from catalyst.utils import set_global_seed\n",
    "import skimage.io\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "latent_dim = 100\n",
    "img_size = 512\n",
    "model_img_size = 384\n",
    "channels = 3\n",
    "n_samples_per_class = 10\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator_auxGAN_512()\n",
    "generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_state_dict(torch.load('../GANs_weights/generator_512_68000.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name: str, model_type: str, weights: str):\n",
    "    model = MelanomaModel.net_mapping(model_name, model_type)\n",
    "    if weights.endswith('.pth'):\n",
    "        model.load_state_dict(\n",
    "            torch.load(weights)\n",
    "        )\n",
    "    elif weights.endswith('.ckpt'):\n",
    "        checkpoint = torch.load(weights, map_location=lambda storage, loc: storage)\n",
    "        pretrained_dict = checkpoint[\"state_dict\"]\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = {k[4:]: v for k, v in pretrained_dict.items() if k[4:] in model_dict}  # net.\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(pretrained_dict)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    print(\"Loaded model {} from checkpoint {}\".format(model_name, weights))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = [\n",
    "    'resnest50d', \n",
    "    'resnest269e', \n",
    "    'resnest101e', \n",
    "    #'seresnext101_32x4d', \n",
    "    'tf_efficientnet_b3_ns', \n",
    "    'tf_efficientnet_b7_ns', \n",
    "    'tf_efficientnet_b5_ns']\n",
    "model_type_list = ['SingleHeadMax'] * len(model_name_list)\n",
    "weights_list = [\n",
    "    '../weights/train_384_balancedW_resnest50d_fold0_heavyaugs_averaged_best_weights.pth',\n",
    "    '../weights/07.09_train_384_balancedW_resnest269e_heavyaugs_averaged_best_weights.pth',\n",
    "    '../weights/03.09_train_384_balancedW_resnest101e_fold0_heavyaugs_averaged_best_weights.pth',\n",
    "    #'../weights/06.18_train_384_balancedW_seresnext101_32x4d_fold0_heavyaugs_averaged_best_weights.pth',\n",
    "    '../weights/06.10_train_384_balancedW_b3_fold0_heavyaugs_averaged_best_weights.pth',\n",
    "    '../weights/05.23_train_384_balancedW_b7_fold0_heavyaugs_averaged_best_weights.pth',\n",
    "    '../weights/03.18_train_384_balancedW_b5_fold0_heavyaugs_averaged_best_weights.pth'\n",
    "]\n",
    "models = [load_model(model_name, model_type, weights) for model_name, model_type, weights in \n",
    "          zip(model_name_list, model_type_list, weights_list)]\n",
    "valid_norm = get_valid_transforms_with_resize(model_img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(torch.cuda.FloatTensor(np.random.normal(0, 1, (n_classes * n_samples_per_class, latent_dim))))\n",
    "# Get labels ranging from 0 to n_classes for n_samples_per_class\n",
    "labels = np.expand_dims(np.array([num for _ in range(n_samples_per_class) for num in range(n_classes)]), 1)\n",
    "labels = Variable(torch.cuda.LongTensor(labels))\n",
    "generated_images = generator(z, labels)\n",
    "generated_images = generated_images.mul(0.5).add(0.5)\n",
    "generated_images = (255*generated_images).float()\n",
    "generated_images = generated_images.detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "normalized_generated_images = [valid_norm(image=image)['image'] for image in generated_images]\n",
    "normalized_generated_images = np.stack(normalized_generated_images)\n",
    "normalized_generated_images = normalized_generated_images.transpose(0, 3, 1, 2)\n",
    "normalized_generated_images = torch.from_numpy(normalized_generated_images)\n",
    "with torch.no_grad():\n",
    "    preds = [nn.Sigmoid()(model(normalized_generated_images.cuda())) for model in models]\n",
    "    preds = torch.stack(preds)    \n",
    "cls_1_pred = preds.mean(axis=0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(n_classes, n_samples_per_class, figsize=(19, 5))\n",
    "ax = ax.flatten()\n",
    "for idx in range(len(generated_images)):\n",
    "    ax[idx].imshow(generated_images[idx].astype(int))\n",
    "    ax[idx].set_title(f'Generated: {labels[idx].cpu().numpy()[0]}\\npredicted: {cls_1_pred[idx][0]:.2f}');  \n",
    "    ax[idx].set_yticklabels([])\n",
    "    ax[idx].set_xticklabels([])  \n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "total_generate_images = 200000\n",
    "n_rounds_generation = total_generate_images // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names_list = []\n",
    "image_class_list = []\n",
    "generated_class_list = []\n",
    "output_folder = '/data/personal_folders/skolchenko/kaggle_melanoma/generated_data_v.004/'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "set_global_seed(42)\n",
    "for genround in tqdm(range(n_rounds_generation)):\n",
    "    z = Variable(torch.cuda.FloatTensor(np.random.normal(0, 1, (n_classes * batch_size // 2, latent_dim))))\n",
    "    labels = np.expand_dims(np.array([num for _ in range(batch_size // 2) for num in range(n_classes)]), 1)\n",
    "    labels = Variable(torch.cuda.LongTensor(labels))\n",
    "    generated_images = generator(z, labels)\n",
    "    generated_images = generated_images.mul(0.5).add(0.5)\n",
    "    generated_images = (255*generated_images).float()\n",
    "    generated_images = generated_images.detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    normalized_generated_images = [valid_norm(image=image)['image'] for image in generated_images]\n",
    "    normalized_generated_images = np.stack(normalized_generated_images)\n",
    "    normalized_generated_images = normalized_generated_images.transpose(0, 3, 1, 2)\n",
    "    normalized_generated_images = torch.from_numpy(normalized_generated_images)\n",
    "    with torch.no_grad():\n",
    "        preds = [nn.Sigmoid()(model(normalized_generated_images.cuda())) for model in models]\n",
    "        preds = torch.stack(preds)    \n",
    "    cls_1_pred = preds.mean(axis=0)[:, 0].cpu().numpy()\n",
    "    image_names = [output_folder+f'generated_{x+genround*batch_size}.jpg' for x in range(batch_size)]\n",
    "    for idx in range(batch_size):\n",
    "        resized_image = cv2.resize(generated_images[idx], (384, 384)).astype(int)\n",
    "        skimage.io.imsave(fname=image_names[idx], arr=resized_image.astype(np.uint8))\n",
    "    image_class_list.extend(cls_1_pred)\n",
    "    image_names_list.extend(image_names)\n",
    "    generated_class_list.extend(labels[:, 0].cpu().numpy())\n",
    "#f, ax = plt.subplots(1, 1, figsize=(20,20))\n",
    "#ax.imshow(utils.make_grid(generated_images).detach().cpu().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_csv = pd.DataFrame({\n",
    "    'image_name': [x.split('/')[-1].split('.')[0] for x in image_names_list], \n",
    "    'target': image_class_list, \n",
    "    'generated_target': generated_class_list})\n",
    "generated_data_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_target(row, thr=0.5):\n",
    "    if row['target'] < thr and row['generated_target'] == 0:\n",
    "        return True\n",
    "    elif row['target'] > thr and row['generated_target'] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "mask_selection = generated_data_csv.apply(get_mask_target, axis=1)\n",
    "generated_data_csv_cleaned = generated_data_csv.loc[mask_selection, :]\n",
    "print(f'Generated {generated_data_csv.shape[0]} samples, but gonna use only {generated_data_csv_cleaned.shape[0]}')\n",
    "generated_data_csv_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(generated_data_csv.loc[generated_data_csv['generated_target']==1, 'target'], alpha=0.4)\n",
    "plt.hist(generated_data_csv.loc[generated_data_csv['generated_target']==0, 'target'], alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(generated_data_csv_cleaned.loc[generated_data_csv_cleaned['generated_target']==1, 'target'], alpha=0.4)\n",
    "plt.hist(generated_data_csv_cleaned.loc[generated_data_csv_cleaned['generated_target']==0, 'target'], alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_csv_cleaned.to_csv('../data/generated_data_v.004.cleaned.csv', index=False)\n",
    "generated_data_csv.to_csv('../data/generated_data_v.004.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('deeplearning': conda)",
   "language": "python",
   "name": "python37564bitdeeplearningconda2f5dcc693383402099797ed40bd3951d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
